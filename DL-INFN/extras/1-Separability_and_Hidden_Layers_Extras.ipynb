{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separability and Hidden Layers: Extras\n",
    "\n",
    "There is another way we can think about what a model is doing at the hidden layer. We can think of each unit of the hidden layer as making it's own decision, and these decisions are combined at the output of the model as if each hidden unit had a vote in determining the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.datasets import make_blobs, make_circles\n",
    "from keras.utils import np_utils\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "    \n",
    "def plot_decision_boundary(model, X, y):\n",
    "    X_max = X.max(axis=0)\n",
    "    X_min = X.min(axis=0)\n",
    "    xticks = np.linspace(X_min[0], X_max[0], 100)\n",
    "    yticks = np.linspace(X_min[1], X_max[1], 100)\n",
    "    xx, yy = np.meshgrid(xticks,\n",
    "                         yticks)\n",
    "    ZZ = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = ZZ[:,0] >= 0.5\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = plt.gca()\n",
    "    ax.contourf(xx, yy, Z, cmap=plt.cm.bwr, alpha=0.2)\n",
    "    ax.scatter(X[:,0], X[:,1], c=y[:,0], alpha=0.4)\n",
    "    \n",
    "X, y = make_circles(n_samples=1000, noise=0.02, factor=0.3)\n",
    "y = np_utils.to_categorical(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "plt.scatter(X[:,0], X[:,1], c=y[:,0], alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "### Exercise 1 - hidden layer decision boundaries\n",
    "\n",
    "If we use ReLU activation in our hidden layer, we can look at units in that layer and consider the part of the input space where the unit is \"on\" (has some positive value) or \"off\" (is 0).\n",
    "\n",
    "Train a model with a ReLU hidden layer and create a truncated model to extract the hidden layer activations. We will use this below to inspect the hidden units.\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build a model with a ReLU hidden layer and softmax output. Fit the model to the circle data.\n",
    "model0 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the plot_decision_boundary function to see what the network learned\n",
    "plot_decision_boundary(model0, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show layers in the model\n",
    "model0.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that `layer_to_extract` below matches the hidden layer activation (after the activation function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "layer_to_extract = 1\n",
    "get_hidden_layer_output = K.function([model0.layers[0].input],\n",
    "                                     [model0.layers[layer_to_extract].output])\n",
    "H = get_hidden_layer_output([X_test])[0]\n",
    "\n",
    "print H.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define a new function to help us see what hidden units are doing. This function plots the decision boundary for multiple hidden units at once. You can provide a list of hidden unit indices as the last argument to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_hidden_decision_boundary(get_output_fn, X, y, hidden_units=[0]):\n",
    "    X_max = X.max(axis=0)\n",
    "    X_min = X.min(axis=0)\n",
    "    xticks = np.linspace(X_min[0], X_max[0], 100)\n",
    "    yticks = np.linspace(X_min[1], X_max[1], 100)\n",
    "    xx, yy = np.meshgrid(xticks, yticks)\n",
    "    \n",
    "    alpha = 0.2 / len(hidden_units)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax = plt.gca()\n",
    "    ax.scatter(X[:,0], X[:,1], c=y[:,0], alpha=0.4)\n",
    "    \n",
    "    for i in hidden_units:\n",
    "        # Find outputs where the specified hidden_unit is \"on\"\n",
    "        ZZ = get_output_fn([np.c_[xx.ravel(), yy.ravel()]])[0]\n",
    "        Z = ZZ[:,i] > 0.0\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=plt.cm.bwr, alpha=alpha)\n",
    "        fig.hold(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the decision boundary of some of the units by using different indices. How do they compare with the decision boundary of the whole model you plotted above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_hidden_decision_boundary(get_hidden_layer_output, X, y, [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try visualizing multiple units at the same time. Notice how there are areas of the input where different units agree and areas where they disagree. Each hidden unit, in a way, has its own idea about how to classify the input. These decisions are not simply added up - they go through more weights and a softmax activation, so they build up the final output in a more complicated way than just adding up. But you should have an intuition about what role the hidden units play in that output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
